{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenML in Python \n",
    "(Work in progress)  \n",
    "Joaquin Vanschoren @joavanschoren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to...\n",
    "- Download datasets and tasks\n",
    "- Use scikit-learn to build classifiers\n",
    "- Upload the results to the server\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication\n",
    "Via API key (e.g. 'rgu9hw1h03g24j974hr3586g4j598fgh')  \n",
    "Always keep it secret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to your OpenML account settings and see 'API authentication' to retrieve your key. \n",
    "<center><img src=\"files/openml_login.png\" width=\"800\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "Via source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#! git clone https://github.com/openml/openml-python.\n",
    "#! cd openml-python\n",
    "#! python setup.py install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, ensemble\n",
    "\n",
    "import openml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# assumes you have your api key in ~/.openml/config\n",
    "# amueller's read/write key that he will throw away later\n",
    "openml.config.apikey='ef035bbd1ca47af239c384aea9124ec5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List ALL the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 of 3307 datasets...\n",
      "   did             name  NumberOfInstances  NumberOfFeatures\n",
      "0    1           anneal              898.0              39.0\n",
      "1    2           anneal              898.0              39.0\n",
      "2    3         kr-vs-kp             3196.0              37.0\n",
      "3    4            labor               57.0              17.0\n",
      "4    5       arrhythmia              452.0             280.0\n",
      "5    6           letter            20000.0              17.0\n",
      "6    7        audiology              226.0              70.0\n",
      "7    8  liver-disorders              345.0               7.0\n",
      "8    9            autos              205.0              26.0\n",
      "9   10            lymph              148.0              19.0\n"
     ]
    }
   ],
   "source": [
    "datasets = openml.datasets.list_datasets()\n",
    "\n",
    "data = pd.DataFrame(datasets)\n",
    "print(\"First 10 of %s datasets...\" % len(datasets))\n",
    "print(data[:10][['did','name','NumberOfInstances','NumberOfFeatures']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset based on any property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 of 738 datasets...\n",
      "    did            name  NumberOfInstances  NumberOfFeatures\n",
      "2     3        kr-vs-kp             3196.0              37.0\n",
      "3     4           labor               57.0              17.0\n",
      "12   13   breast-cancer              286.0              10.0\n",
      "14   15        breast-w              699.0              10.0\n",
      "23   24        mushroom             8124.0              23.0\n",
      "24   25           colic              368.0              28.0\n",
      "26   27           colic              368.0              23.0\n",
      "28   29        credit-a              690.0              16.0\n",
      "30   31        credit-g             1000.0              21.0\n",
      "32   33  cylinder-bands              540.0              40.0\n"
     ]
    }
   ],
   "source": [
    "bin_data = data.loc[data['NumberOfClasses'] == 2]\n",
    "print(\"First 10 of %s datasets...\" % len(bin_data))\n",
    "print(bin_data[:10][['did','name', 'NumberOfInstances','NumberOfFeatures']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset based on any property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 of 738 datasets...\n",
      "       did                          name  NumberOfInstances\n",
      "1302  1588                           w8a            64700.0\n",
      "2421  4533  KEGGMetabolicReactionNetwork            65554.0\n",
      "1305  1591                     connect-4            67557.0\n",
      "423    554                     mnist_784            70000.0\n",
      "1293  1578                      real-sim            72309.0\n",
      "1062  1213                       BNG(mv)            78732.0\n",
      "2420  4532                         higgs            98050.0\n",
      "247    357                vehicle_sensIT            98528.0\n",
      "1080  1242                   vehicleNorm            98528.0\n",
      "1307  1593       SensIT-Vehicle-Combined            98528.0\n"
     ]
    }
   ],
   "source": [
    "big_data = data.loc[data['NumberOfInstances'] > 60000]\n",
    "big_data = big_data.sort_values(by='NumberOfInstances', ascending=True)\n",
    "print(\"First 10 of %s datasets...\" % len(bin_data))\n",
    "print(big_data[:10][['did','name', 'NumberOfInstances']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download a specific dataset. This is done based on the dataset ID (called 'did' in the table above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'oml:data_set_description'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-8756286212b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopenml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m61\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"This is dataset '%s', the target feature is called '%s'\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_target_attribute\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"URL: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/envs/open-ml/lib/python3.5/site-packages/openml/datasets/functions.py\u001b[0m in \u001b[0;36mget_dataset\u001b[1;34m(did)\u001b[0m\n\u001b[0;32m    237\u001b[0m                          \"cast to an Integer.\")\n\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m     \u001b[0mdescription\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_dataset_description\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m     \u001b[0marff_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_dataset_arff\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdescription\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/envs/open-ml/lib/python3.5/site-packages/openml/datasets/functions.py\u001b[0m in \u001b[0;36mget_dataset_description\u001b[1;34m(did)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_get_cached_dataset_description\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mOpenMLCacheException\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/envs/open-ml/lib/python3.5/site-packages/openml/datasets/functions.py\u001b[0m in \u001b[0;36m_get_cached_dataset_description\u001b[1;34m(did)\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mxmltodict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_xml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"oml:data_set_description\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     raise OpenMLCacheException(\"Dataset description for did %d not \"\n",
      "\u001b[1;31mKeyError\u001b[0m: 'oml:data_set_description'"
     ]
    }
   ],
   "source": [
    "dataset = openml.datasets.get_dataset(61)\n",
    "\n",
    "print(\"This is dataset '%s', the target feature is called '%s'\" % (dataset.name, dataset.default_target_attribute))\n",
    "print(\"URL: %s\" % dataset.url)\n",
    "print(dataset.description[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(vars(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y, attribute_names = dataset.get_dataset(target=dataset.default_target_attribute, return_attribute_names=True)\n",
    "iris = pd.DataFrame(X, columns=attribute_names)\n",
    "iris['class'] = y\n",
    "print(iris[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have fun with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris.plot(kind='scatter', x='petallength', y='petalwidth', c='class', s=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a scikit-learn model on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = openml.datasets.get_dataset(61)\n",
    "X, y = dataset.get_dataset(target=dataset.default_target_attribute)\n",
    "clf = ensemble.RandomForestClassifier()\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper code by Gilles Louppe\n",
    "# % matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_surface(clf, X, y, \n",
    "                 xlim=(0, 7), ylim=(0, 3), n_steps=250, \n",
    "                 subplot=None, show=True):\n",
    "    if subplot is None:\n",
    "        fig = plt.figure()\n",
    "    else:\n",
    "        plt.subplot(*subplot)\n",
    "        \n",
    "    xx, yy = np.meshgrid(np.linspace(xlim[0], xlim[1], n_steps), \n",
    "                         np.linspace(ylim[0], ylim[1], n_steps))\n",
    "    \n",
    "    if hasattr(clf, \"decision_function\"):\n",
    "        z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "    else:\n",
    "        z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "        \n",
    "    z = z.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, z, alpha=0.8, cmap=plt.cm.RdBu_r)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y)\n",
    "    plt.xlim(*xlim)\n",
    "    plt.ylim(*ylim)\n",
    "    \n",
    "    if show:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_2d = X[:,2:4]\n",
    "clf.fit(X_2d, y)\n",
    "plot_surface(clf, X_2d, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also ask which features are categorical to do your own encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y, categorical = dataset.get_dataset(target=dataset.default_target_attribute,return_categorical_indicator=True)\n",
    "enc = preprocessing.OneHotEncoder(categorical_features=categorical)\n",
    "X = enc.fit_transform(X)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run benchmarks consistently (also across studies and tools), OpenML offers Tasks, which include specific train-test splits and other information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List ALL the tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "task_list = openml.tasks.list_tasks()\n",
    "\n",
    "tasks = pd.DataFrame(task_list)\n",
    "print(\"First 5 of %s tasks:\" % len(tasks))\n",
    "print(tasks[:5][['tid','did','name','task_type','estimation_procedure']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "task = openml.tasks.get_task(10)\n",
    "print(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a scikit-learn classifier on the task (using the right splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from openml.runs import run_task\n",
    "\n",
    "clf = ensemble.RandomForestClassifier()\n",
    "run = run_task(task, clf)\n",
    "print(\"RandomForest has run on the task.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the run to the OpenML server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xmltodict\n",
    "\n",
    "return_code, response = run.publish()\n",
    "\n",
    "if(return_code == 200):\n",
    "    response_dict = xmltodict.parse(response)\n",
    "    run_id = response_dict['oml:upload_run']['oml:run_id']\n",
    "    print(\"Uploaded run with id %s\" % (run_id))\n",
    "    print(\"Check it at www.openml.org/r/%s\" % (run_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More to come soon..."
   ]
  }
 ],
 "metadata": {
  "colabVersion": "0.1",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
